{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970911d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Créez des listes pour stocker les données\n",
    "Noms = []\n",
    "Adresses = []\n",
    "Numeros = []\n",
    "Secteurs = []\n",
    "Liens = []\n",
    "Pays = []\n",
    "Villes = []\n",
    "Sites = []\n",
    "Tel = []\n",
    "Numeros = []\n",
    "\n",
    "# Liste des pays avec leurs codes\n",
    "pays = [\n",
    "    \"za\", \"gn\", \"cm\", \"dz\", \"ao\", \"bj\", \"bw\", \"bf\", \"cm\", \"cg\", \"cd\", \"ci\", \"dj\", \"eg\", \"et\", \"ga\", \"gh\",\n",
    "    \"gn\", \"ke\", \"lr\", \"mg\", \"mw\", \"ml\", \"ma\", \"mu\", \"mz\", \"na\", \"ne\", \"ng\", \"ug\", \"cf\", \"rw\", \"sn\", \"so\",\n",
    "    \"tz\", \"tg\", \"tn\"\n",
    "]\n",
    "\n",
    "import re\n",
    "\n",
    "for code in pays:\n",
    "    for page_num in range(1, 749):  # Adjust the number of pages as needed\n",
    "        url = f\"https://www.goafricaonline.com/{code}/annuaire-resultat?type=company&p={page_num}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find all articles containing company information\n",
    "            articles = soup.find_all('article', {'data-role': 'company'})\n",
    "\n",
    "            for article in articles:\n",
    "                # Extract information from each article\n",
    "                company_name = article.find('h2').find('a').text.strip()\n",
    "\n",
    "                # Check if the industry information is available\n",
    "                industry_element = article.find('div', {'class': 'text-14 text-brand-blue'})\n",
    "                industry = industry_element.text.strip() if industry_element else ''\n",
    "\n",
    "                address_element = article.find('address')\n",
    "                address_text = address_element.text.strip() if address_element else ''\n",
    "\n",
    "                # Extract the href attribute\n",
    "                company_link = article.find('h2').find('a')['href']\n",
    "\n",
    "                phone_number_element = article.find('a', {'href': True, 'data-collect-event-on-click': True})\n",
    "                phone = phone_number_element.text.strip() if phone_number_element else ''\n",
    "\n",
    "                # Extract city and country from address_text\n",
    "                address_parts = address_text.split('-')\n",
    "\n",
    "                if len(address_parts) > 1:\n",
    "                    country = address_parts[1].strip()  # Last word before the \"-\"\n",
    "                    city_match = re.search(r'[A-Z](?=[^A-Z]*$)', address_parts[0].strip())\n",
    "                    if city_match:\n",
    "                        start_index = city_match.start()\n",
    "                        city = address_parts[0].strip()[start_index:].strip()\n",
    "                    else:\n",
    "                        city = ''\n",
    "                # Additional information (optional)\n",
    "                description_element = article.find('div', {'class': 'text-gray-700 text-14'})\n",
    "                description = description_element.text.strip() if description_element else ''\n",
    "                \n",
    "                company_response = requests.get(company_link)\n",
    "                if company_response.status_code == 200:\n",
    "                    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "                    # Extraction du site web\n",
    "                    website_link_element = company_soup.find('a', class_='font-bold text-link block')\n",
    "\n",
    "                    if website_link_element:\n",
    "                        website_link = website_link_element['href']\n",
    "                    else:\n",
    "                        website_link = \"\"\n",
    "\n",
    "                    phone_numbers_elements = company_soup.find_all('a', class_='text-13 text-gray-700 underline hover:no-underline')\n",
    "\n",
    "                    if phone_numbers_elements:\n",
    "                        for phone_number_element in phone_numbers_elements:\n",
    "                            phone_number = phone_number_element['href']\n",
    "                            \n",
    "                    else:\n",
    "                        phone_number = \"\"\n",
    "                else:\n",
    "                    print(f\"Erreur: {company_response.status_code}\")\n",
    "                    \n",
    "\n",
    "                # Append the extracted information to the lists\n",
    "                Noms.append(company_name)\n",
    "                Secteurs.append(industry)\n",
    "                Adresses.append(address_text)\n",
    "                Sites.append(website_link)\n",
    "                Numeros.append(phone_number)\n",
    "                Tel.append(phone)\n",
    "                Liens.append(company_link)  # Add the company link\n",
    "                Villes.append(city)  # Add the city\n",
    "                Pays.append(country)  # Add the countr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb68d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame using pandas\n",
    "data = {'Nom': Noms, 'Secteur': Secteurs, 'Sites':Sites, 'Adresse': Adresses, 'Numero': Numeros,'Tel':Tel, 'Liens': Liens, 'Ville': Villes, 'Pays': Pays}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to Excel file\n",
    "df.to_excel(\"output.xlsx\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef7078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Create lists to store the data\n",
    "Noms = []\n",
    "Adresses = []\n",
    "Numeros = []\n",
    "Secteurs = []\n",
    "Liens = []\n",
    "Pays = []\n",
    "Villes = []\n",
    "Sites = []\n",
    "Tel = []\n",
    "\n",
    "# List of countries with their codes\n",
    "pays = [\n",
    "    \"za\", \"gn\", \"cm\", \"dz\", \"ao\", \"bj\", \"bw\", \"bf\", \"cm\", \"cg\", \"cd\", \"ci\", \"dj\", \"eg\", \"et\", \"ga\", \"gh\",\n",
    "    \"gn\", \"ke\", \"lr\", \"mg\", \"mw\", \"ml\", \"ma\", \"mu\", \"mz\", \"na\", \"ne\", \"ng\", \"ug\", \"cf\", \"rw\", \"sn\", \"so\",\n",
    "    \"tz\", \"tg\", \"tn\"\n",
    "]\n",
    "\n",
    "for code in pays:\n",
    "    for page_num in range(1, 749):  # Adjust the number of pages as needed\n",
    "        url = f\"https://www.goafricaonline.com/{code}/annuaire-resultat?type=company&p={page_num}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find all articles containing company information\n",
    "            articles = soup.find_all('article', {'data-role': 'company'})\n",
    "\n",
    "            for article in articles:\n",
    "                # Extract information from each article\n",
    "                company_name = article.find('h2').find('a').text.strip()\n",
    "\n",
    "                # Check if the industry information is available\n",
    "                industry_element = article.find('div', {'class': 'text-14 text-brand-blue'})\n",
    "                industry = industry_element.text.strip() if industry_element else ''\n",
    "\n",
    "                address_element = article.find('address')\n",
    "                address_text = address_element.text.strip() if address_element else ''\n",
    "\n",
    "                # Extract the href attribute\n",
    "                company_link = article.find('h2').find('a')['href']\n",
    "\n",
    "                phone_number_element = article.find('a', {'href': True, 'data-collect-event-on-click': True})\n",
    "                phone = phone_number_element.text.strip() if phone_number_element else ''\n",
    "\n",
    "                # Extract city and country from address_text\n",
    "                address_parts = address_text.split('-')\n",
    "\n",
    "                if len(address_parts) > 1:\n",
    "                    country = address_parts[1].strip()  # Last word before the \"-\"\n",
    "                    city_match = re.search(r'[A-Z](?=[^A-Z]*$)', address_parts[0].strip())\n",
    "                    if city_match:\n",
    "                        start_index = city_match.start()\n",
    "                        city = address_parts[0].strip()[start_index:].strip()\n",
    "                    else:\n",
    "                        city = ''\n",
    "                else:\n",
    "                    country = ''\n",
    "                    city = ''\n",
    "\n",
    "                # Additional information (optional)\n",
    "                description_element = article.find('div', {'class': 'text-gray-700 text-14'})\n",
    "                description = description_element.text.strip() if description_element else ''\n",
    "\n",
    "                company_response = requests.get(company_link)\n",
    "                if company_response.status_code == 200:\n",
    "                    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "                    # Extraction du site web\n",
    "                    website_link_element = company_soup.find('a', class_='font-bold text-link block')\n",
    "\n",
    "                    if website_link_element:\n",
    "                        website_link = website_link_element['href']\n",
    "                    else:\n",
    "                        website_link = \"\"\n",
    "\n",
    "                    phone_numbers_elements = company_soup.find_all('a', class_='text-13 text-gray-700 underline hover:no-underline')\n",
    "                    phone_numbers = [phone_number_element['href'] for phone_number_element in phone_numbers_elements]\n",
    "\n",
    "                    phone_number = ', '.join(phone_numbers) if phone_numbers else \"\"\n",
    "                else:\n",
    "                    print(f\"Erreur: {company_response.status_code}\")\n",
    "                    website_link = \"\"\n",
    "                    phone_number = \"\"\n",
    "\n",
    "                # Append the extracted information to the lists\n",
    "                Noms.append(company_name)\n",
    "                Secteurs.append(industry)\n",
    "                Adresses.append(address_text)\n",
    "                Sites.append(website_link)\n",
    "                Numeros.append(phone_number)\n",
    "                Tel.append(phone)\n",
    "                Liens.append(company_link)  # Add the company link\n",
    "                Villes.append(city)  # Add the city\n",
    "                Pays.append(country)  # Add the country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f993ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91adff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da26f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Create lists to store the data\n",
    "Noms = []\n",
    "Adresses = []\n",
    "Numeros = []\n",
    "Secteurs = []\n",
    "Liens = []\n",
    "Pays = []\n",
    "Villes = []\n",
    "Sites = []\n",
    "Tel = []\n",
    "\n",
    "# List of countries with their codes\n",
    "pays = [\n",
    "    \"za\", \"gn\", \"cm\", \"dz\", \"ao\", \"bj\", \"bw\", \"bf\", \"cm\", \"cg\", \"cd\", \"ci\", \"dj\", \"eg\", \"et\", \"ga\", \"gh\",\n",
    "    \"gn\", \"ke\", \"lr\", \"mg\", \"mw\", \"ml\", \"ma\", \"mu\", \"mz\", \"na\", \"ne\", \"ng\", \"ug\", \"cf\", \"rw\", \"sn\", \"so\",\n",
    "    \"tz\", \"tg\", \"tn\"\n",
    "]\n",
    "\n",
    "for code in pays:\n",
    "    for page_num in range(1, 749):  # Adjust the number of pages as needed\n",
    "        url = f\"https://www.goafricaonline.com/{code}/annuaire-resultat?type=company&p={page_num}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find all articles containing company information\n",
    "            articles = soup.find_all('article', {'data-role': 'company'})\n",
    "\n",
    "            for article in articles:\n",
    "                # Extract information from each article\n",
    "                company_name = article.find('h2').find('a').text.strip()\n",
    "\n",
    "                # Check if the industry information is available\n",
    "                industry_element = article.find('div', {'class': 'text-14 text-brand-blue'})\n",
    "                industry = industry_element.text.strip() if industry_element else ''\n",
    "\n",
    "                address_element = article.find('address')\n",
    "                address_text = address_element.text.strip() if address_element else ''\n",
    "\n",
    "                # Extract the href attribute\n",
    "                company_link = article.find('h2').find('a')['href']\n",
    "\n",
    "                phone_number_element = article.find('a', {'href': True, 'data-collect-event-on-click': True})\n",
    "                phone = phone_number_element.text.strip() if phone_number_element else ''\n",
    "\n",
    "                # Extract city and country from address_text\n",
    "                address_parts = address_text.split('-')\n",
    "\n",
    "                if len(address_parts) > 1:\n",
    "                    country = address_parts[1].strip()  # Last word before the \"-\"\n",
    "                    city_match = re.search(r'[A-Z](?=[^A-Z]*$)', address_parts[0].strip())\n",
    "                    if city_match:\n",
    "                        start_index = city_match.start()\n",
    "                        city = address_parts[0].strip()[start_index:].strip()\n",
    "                    else:\n",
    "                        city = ''\n",
    "                else:\n",
    "                    country = ''\n",
    "                    city = ''\n",
    "\n",
    "                # Additional information (optional)\n",
    "                description_element = article.find('div', {'class': 'text-gray-700 text-14'})\n",
    "                description = description_element.text.strip() if description_element else ''\n",
    "\n",
    "                company_response = requests.get(company_link)\n",
    "                if company_response.status_code == 200:\n",
    "                    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "                    # Extraction du site web\n",
    "                    website_link_element = company_soup.find('a', class_='font-bold text-link block')\n",
    "\n",
    "                    if website_link_element:\n",
    "                        website_link = website_link_element['href']\n",
    "                    else:\n",
    "                        website_link = \"\"\n",
    "\n",
    "                    phone_numbers_elements = company_soup.find_all('a', class_='text-13 text-gray-700 underline hover:no-underline')\n",
    "                    phone_numbers = [phone_number_element['href'] for phone_number_element in phone_numbers_elements]\n",
    "\n",
    "                    phone_number = ', '.join(phone_numbers) if phone_numbers else \"\"\n",
    "                else:\n",
    "                    print(f\"Erreur: {company_response.status_code}\")\n",
    "                    website_link = \"\"\n",
    "                    phone_number = \"\"\n",
    "\n",
    "                # Append the extracted information to the lists\n",
    "                Noms.append(company_name)\n",
    "                Secteurs.append(industry)\n",
    "                Adresses.append(address_text)\n",
    "                Sites.append(website_link)\n",
    "                Numeros.append(phone_number)\n",
    "                Tel.append(phone)\n",
    "                Liens.append(company_link)  # Add the company link\n",
    "                Villes.append(city)  # Add the city\n",
    "                Pays.append(country)  # Add the country\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Nom': Noms,\n",
    "    'Secteur': Secteurs,\n",
    "    'Adresse': Adresses,\n",
    "    'Site': Sites,\n",
    "    'Numero': Numeros,\n",
    "    'Tel': Tel,\n",
    "    'Lien': Liens,\n",
    "    'Ville': Villes,\n",
    "    'Pays': Pays\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('company_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521cd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
